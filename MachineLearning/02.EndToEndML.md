# End-to-End Machine Learning Project
## 01. Look at the big picture - define the goal
Learn all that you can about the context of your project:
* Why do the sponsors want the project in the first place? What do they lack, and what do they need?
* What are they doing to solve the problem now, and why isn’t that good enough?
* What resources will you need: – what kind of data and how much staff? – Will you have domain experts to collaborate with, and – what are the computational resources?
* How do the project sponsors plan to deploy your results? What are the constraints that have to be met for successful deployment?

Once you have a good idea of the project’s goals, you can focus on collecting data to meet those goals, or wrangling with existing data to meet those goals.## 01. Get the data

## 02. Get the data.
This generally most time consuming stage and most important. Ans while we collect data, we need to ask:
* What data is available to me?
* Will it help me solve the problem?
* Is it enough?
* Is the data quality good enough?

## 03. Discover and visualize the data to gain insights.
For this step we do  Data Exploration and Anslysis

## 04. Prepare the data for Machine Learning algorithms.
In this step we do
* Data Cleaning
* Handling Text and Categorical Attributes
* Feature Scaling (min-max scaling vs standardisation)
* Transformation Pipelines (specify the order of these transformations)

## 05. Select a model and train it.
This stage is where you try to extract useful insights from the data in order to achieve your goals.

There will be overlap and back and forth between the modeling stage and the data cleaning stage to try find the best way to represent the data and the best form in which to model it.

The most common data science modeling tasks are these: 
* Classification - Deciding if something belongs to one category or another.
* Scoring- Predicting or estimating a numeric value, such as a price or probability
* Ranking- Learning to order items by preferences
* Clustering- Grouping items into most-similar groups
* Finding relations- Finding correlations or potential causes of effects seen in the data
* Characterization- Very general plotting and report generation from data

To select a model from multiple models, we can use `Cross-Validation`, `validation set`
## 06. Fine-tune your model.
Some model you trained in step 5 may require your to tune hyperparamaters that give the best model perfromace. A common way to to it is by `Gird Cross Validation Search`.

Or `Randomized Cross Validation Search` when the hyperparameter search space is large

## 07. Present your solution.
After meeting the success criteria of the project, you need to present your results to your project sponsor and other stakeholders.

Documents the model for those who need to use the model for running, using and maintaining the mode once it has been deployed.

Document for Business-oriented audience - understand the impact of finding in terms of business metrics.

Model Presentation for end-users should emphasis on how the model will help them do their job better.

Model Presentation for operations staff should emphasis on the impact of the model on the resources they responsible for.

## 08. Launch, monitor, and maintain your system.
This stage comes after putting the model in the operations.

Ensure the model run smoothly and won’t make disastrous unsupervised decisions.

Ensure model can be updated as its environment change.

# Feature scalling
Typically data collected in real world have difference range and scale. Which makes some model perfrom badly, as reasone like large range feature dominont other features. And algorithms like GD, NN will converge faster after feature scalling.

2 Types of feature scalling:
1. normalization: rescaling into a range (min, max), such as (-1, 1)
2. standardization: rescaling the feature with mean 0 and varence 1.

### `Apply feature scaling on test set using scaling parameters from train set`
This is because a model shall be applied on unseen data which is in general not available at the time the model is built. The validation process simulates this.

 So in order to get a good estimate of the model quality (and generalization power) one needs to restrict the calculation of the normalization parameters (mean and variance) to the training set.