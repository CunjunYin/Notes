In this chapter, we start to look at how Machine Learning algorithms work, starting with some of the simplest.

# Linear Regression
This is a linear model which makes a prediction by simply computing a weighted sum of the input features, plus a constant called the bias term (also called the intercept term), 

y = θ<sub>0</sub> + θ<sub>1</sub>x<sub>1</sub> + θ<sub>2</sub>x<sub>2</sub> + ... + θ<sub>n</sub>x<sub>n</sub>

* y is the predicted value
* n is the number of features
* x<sub>i</sub> is the i th feature value

θ<sub>j</sub> is the j<sup>th</sup> model parameter

## Linear Regression: vectorized form of model
y = h<sub>θ</sub>(x) = θ<sup>T</sup>x

* y is the predicted value
* θ is the model’s parameter vector, containing the bias term θ<sub>0</sub> and the feature weights θ<sub>1</sub> to θ<sub>n</sub>. i.e., θ = (θ<sub>0</sub>, θ<sub>1</sub>, · · · , θ<sub>n</sub>)<sup>T</sup>.
* x is the instance’s feature vector, containing x<sub>0</sub> to x<sub>n</sub>, with x<sub>0</sub> always equal to 1. That is, x = (x<sub>0</sub>, x<sub>1</sub>, · · · , x<sub>n</sub>)<sup>T</sup>.
* θ<sup>T</sup>x is the dot product of θ and x.
* h<sub>θ</sub> is the hypothesis function, using the model parameters θ.
  
## Training the model
Training a model means setting its parameters so that the model best fits the training set.
* For this purpose, we first need a measure of how well (or poorly) the model fits the training data. In Chapter 2 we saw that the most common performance measure of a regression model is the Root Mean Square Error (RMSE).
* Therefore, to train a Linear Regression model, you need to find the value of θ that minimizes the RMSE.
* In practice, it is simpler to minimize the Mean Square Error (MSE) than the RMSE, and it leads to the same result (because the value that minimizes a function also minimizes its square root).

## Linear Regression: the Normal Equation
To find the value of `θ` that minimizes the cost function, there is a closed-form solution—in other words, a mathematical equation that gives the result directly. This is called the Normal Equation.

<span class="hat">θ</span> = (X<sup>T</sup> X)<sup>-1</sup>X<sup>T</sup>y


* `X` is a m × (n + 1) matrix – the `i`<sub>th</sub> row of `X` is the training instance x(i)
* <span class="hat">θ</span> is the value that minimizes the cost function;
* `y` is the vector of target values containing `y`<sup>`(1)`</sup> to `y`<sup>`(m)`</sup>

Once the optimal model parameter <span class="hat">θ</span> is known, given a new test instance x<sub>test</sub>, we can predict y<sub>test</sub> using the formula:

y<sub>test</sub> = <span class="hat">θ</span><sup>T</sup> x<sub>test</sub>

Disadvatage is not suitable for large dataset with n dimension feature, as it's too slow

# Gradient Descent
The general idea of Gradient Descent is to tweak parameters iteratively in order to minimize a cost function. It measures the local gradient of the error function with regards to the parameter vector `θ`, and it goes in the direction of descending gradient. Once the gradient is zero, you have reached a minimum! In general
1. start by filling `θ` with random values -random initialization
2. improve `θ` gradually, taking one baby step at a time, each step attempting to decrease the cost function
3. until the algorithm converges to a minimum

### Partial Derivatives and the gradient vector
Gradient Descent use Partial Derivatives to compute the gradient of the cost function with regards to each model parameter θ<sub>j</sub>.

1. calculate how much the cost function will change if you change θ<sub>j</sub> just a little bit.

θ<sub>(next step)</sub> = θ − η∇<sub>θ</sub>MSE<sub>θ</sub>

## Ways to do Gradient Descent
### `Batch GD`
Uses the whole training set to compute the gradients at every step, which makes it very slow when the training set
is large.

### `Stochastic GD`
Just picks a random instance in the training set at every step and computes the gradients based only on that single instance. 

Makes the algorithm much faster since it has very little data to manipulate at every iteration. Also possible to train on huge training sets.

### `Mini-batch GD`
At each step, instead of computing the gradients based on the full training set (as in `Batch GD`) or based on just one instance (as in `Stochastic GD`), computes the gradients on small random sets of instances (`mini-batches`). Get a performance boost from hardware optimization of matrix operations (GPUs).

# Polynomial Regression
Same as linear regression but the relationship between x and y is not linear.

# Bias/Variance Tradeoff
A model’s generalization error can be expressed as the sum of 3 different errors:

### `Bias` 
this part of the generalization error is due to wrong assumption, e.g. assumption that the data is linear when it is quadratic. A high bias model tends to give underfitting problem.

### `Variance`
this part of the generalization error is due to the model’s excessive sensitivity to small variation in the training data. A high variance model tends to give overfitting problem.

### `Irreducible error`
This part is due to the noisiness of the data. The only way to reduce this error is to clean up the data.
* Increasing a model’s complexity will typically increase its variance and reduce its bias.
* Reducing a model’s complexity increases its bias and reduces its variance.

# Regularised Linear Model
When a model expercing overfitting issue, a good way to solve this issue is by regularize the model - constrain it). For example, a simple way to regularize a polynomial model is to reduce the number of polynomial degrees.

Three different ways to constrain the linear model.
## Ridge Regression
Ridge Regression is a regularized version of Linear Regression, with the regularization term equalling to

regularization = aΣθ<sup>2</sup><sub>i</sub>

By adding this regularization term, forces the learning algorithm to not only fit the data but also keep the model weights as small as possible.

    the regularization term should only be added to the cost function during training.

Once the model is trained, you evaluate the model’s performance using the unregularized performance measure.

The `Ridge Regression cost function` is:
J(θ) = MSE(θ) + α<sup>1</sup>/<sub>2</sub> a Σ θ<sup>2</sup><sub>i</sub>

>  As α increase, the the weight will be more important, thus relularise more.

## Lasso Regression
Uses |θ<sub>i</sub>| instead of θ<sup>2</sup><sub>i</sub> for the regularization term.

Lasso tends eliminate the weight of the least important feature, so with a small α, it can regularize the regression well. Thuse `large α` will cause underfiting

## Elastic Net
Elastic Net is a middle ground between Ridge Regression and Lasso Regression. It combines both regularization terms together. 

The Elastic Net cost function is:

J(θ) = MSE(θ) + rα Σ |θ<sub>i</sub>| + <sup>1 - r</sup>/<sub>2</sub> α Σ θ<sup>2</sup><sub>i</sub>

where we now have hyperparameters  `α` and `r`as two regularization coefficients.

> It has been found to have predictive power better than Lasso, while still performing feature selectio

## Early Stopping
Another way to regularize iterative learning algorithms such as Gradient Descent is to `stop training as soon as the validation error reaches a minimum`.
# Logistic Regression
Logistic Regression is commonly used to estimate the probability that an instance belongs to a particular class

If the estimated probability is greater than 50%, then the model predicts that the instance belongs to that class (called the positive class, labelled “1”), or else it predicts that it does not (i.e., it belongs to the negative class, labelled “0”) - `binary classifier`.

Just like a Linear Regression model, a Logistic Regression model computes a weighted sum of the input features

The probability pˆ estimated by the Logistic Regression model is given by: 

<span class="hat">p</span> = h<sub>θ</sub>(x) = σ(θ<sup>T</sup> x)

where the logistic function σ(t) is defined as follows:

σ(t) = <sup>1</sup>/<sub>(1 + exp(−t))</sub>

So the Logistic Regression model prediction is:

<span class="hat">y</span> = 0 if <span class="hat">p</span> < 0.5

<span class="hat">y</span> = 0 if <span class="hat">p</span> >= 0.5

### Training and Cost Function

J(θ) = −<sup>1</sup>/<sub>m</sub> [y<sup>(i)</sup> log( <span class="hat">p</span><sup>(i)</sup> ) + (1 − y<sup>(i)</sup>) log(1 − <span class="hat">p</span><sup>(i)</sup>)]

This cost function estimates high probabilities for positive instances (y = 1) and low probabilities for negative instances. So by average over all instances, GD is guaranteed to find the global minimum.

    Sometime GD will stuck in local minumum

# Softmax Regression
The Softmax regression is a form of logistic regression that normalizes an input value into a vector of values that follows a probability distribution whose total sums up to 1.

The Softmax Regression model first computes a score for each class k,  then estimates the probability p(k) of each class by applying the softmax function

